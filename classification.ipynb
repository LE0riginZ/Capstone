{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import packages</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure TensorFlow to use GPU for training\n",
    "tf.config.list_physical_devices('GPU') \n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#Set GPU memory limit so my GPU doesn't crash\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create class to record time taken to train the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class to record time taken to train per epoch\n",
    "class TimingCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, logs={}):\n",
    "        self.logs=[]\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(timer()-self.starttime)\n",
    "\n",
    "cb = TimingCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create train and test folder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a folder each time the set of code is run to sort dataset into train and test\n",
    "day = date.today()\n",
    "formatDate = day.strftime(\"%b-%d-%Y\")\n",
    "\n",
    "#create folder with current date to group predictions ran in a day together, if it does not exists\n",
    "if os.path.isdir('Prediction (' + formatDate + ')') is False:\n",
    "    folder = os.mkdir('Prediction (' + formatDate + ')')\n",
    "folder = 'Prediction (' + formatDate + ')'\n",
    "\n",
    "#looping through to find if destination folder exists\n",
    "i = 1\n",
    "while True:\n",
    "    if os.path.isdir(folder + '/Battery Images - ' + str(i)) is False:\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "#destination path for unsorted folder\n",
    "destination = folder + '/Battery Images - ' + str(i)\n",
    "\n",
    "#source path for unsorted folder\n",
    "source = 'Battery Images/'\n",
    "\n",
    "#duplicate the unsorted folder from source to destination\n",
    "shutil.copytree(source, destination)\n",
    "\n",
    "os.mkdir(destination + '/train')\n",
    "os.mkdir(destination + '/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Sort dataset into train and test folder</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split images into training (80%) and testing (20%) and return both\n",
    "def split(data):\n",
    "    num = int(len(data) * 0.8)\n",
    "    random.shuffle(data)\n",
    "    return data[:num], data[num:]\n",
    "\n",
    "dir = os.chdir(destination)\n",
    "for category in os.listdir(dir):\n",
    "    #skip the iteration if folder is \"train\" or \"test\"\n",
    "    skip = ['train', 'test']\n",
    "    if category in skip:\n",
    "        continue\n",
    "    \n",
    "    shutil.move(f'{category}', 'train')\n",
    "    #create a subfolder with the same name in test\n",
    "    os.mkdir(f'test/{category}')\n",
    "\n",
    "    #get the images in each folder (battery type) for spltting of data into training and testing\n",
    "    img = os.listdir(f'train/{category}')\n",
    "    training, testing = split(img)\n",
    "    \n",
    "    for file in testing:\n",
    "        shutil.move(f'train/{category}/{file}', f'test/{category}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>a) Simple sequential model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(224, 224, 3)))  # 250x250 RGB images\n",
    "model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "model.add(layers.GlobalMaxPooling2D())\n",
    "model.add(layers.Dense(5, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>b) Transfer Learning - MobileNet</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"include_top=False argument\" will load a network that excluding the classification layers at the top\n",
    "mobile = tf.keras.applications.mobilenet.MobileNet(input_shape = (224, 224, 3), include_top = False, weights = \"imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>c) Transfer Learning - MobileNetV2</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"include_top=False argument\" will load a network that excluding the classification layers at the top\n",
    "mobile = tf.keras.applications.MobileNetV2(input_shape = (224, 224, 3), include_top = False, weights = \"imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>c) Transfer Learning - VGG16</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"include_top=False argument\" will load a network that excluding the classification layers at the top\n",
    "mobile = tf.keras.applications.vgg16.VGG16(input_shape = (224, 224, 3), include_top = False, weights = \"imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>d) Transfer Learning - VGG19</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"include_top=False argument\" will load a network that excluding the classification layers at the top\n",
    "mobile = tf.keras.applications.vgg19.VGG19(input_shape = (224, 224, 3), include_top = False, weights = \"imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>e) Transfer Learning - ResNet50</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"include_top=False argument\" will load a network that excluding the classification layers at the top\n",
    "mobile = tf.keras.applications.resnet.ResNet50(input_shape = (224, 224, 3), include_top = False, weights = \"imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>f) Transfer Learning - ResNet50V2</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"include_top=False argument\" will load a network that excluding the classification layers at the top\n",
    "mobile = tf.keras.applications.ResNet50V2(input_shape = (224, 224, 3), include_top = False, weights = \"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer in mobile.layers[:-2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "x = mobile(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(5, activation=\"softmax\")(x)    \n",
    "model = keras.Model(inputs, output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Process data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'train'\n",
    "test_path = 'test'\n",
    "\n",
    "#for data augmentation on training data\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.mobilenet.preprocess_input,\n",
    "    validation_split=0.2,\n",
    "    rotation_range = 10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.2, # Randomly zoom image \n",
    "    width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range = 0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip = True,  # randomly flip images\n",
    "    vertical_flip = False,    # randomly flip images\n",
    "    )  \n",
    "\n",
    "#takes images from directory path and generates batches of augmented data\n",
    "train = datagen.flow_from_directory(\n",
    "    directory=train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    subset='training',\n",
    "    shuffle = False)\n",
    "\n",
    "#for validation data\n",
    "validation_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input, \n",
    "                                        validation_split=0.2)\n",
    "\n",
    "validation = validation_batches.flow_from_directory(\n",
    "    directory=train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    subset='validation',\n",
    "    shuffle = False)\n",
    "\n",
    "#for test data\n",
    "test = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input)\\\n",
    ".flow_from_directory(directory=test_path, target_size=(224,224), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.006), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#more epochs for better results\n",
    "result = model.fit(x=train, validation_data=validation, epochs=150, verbose=2, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluate Test data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(cb.logs) / 150)\n",
    "\n",
    "testLoss, testAcc = model.evaluate(test)\n",
    "print('''\n",
    "Test Loss: {}\n",
    "Test Accuracy: {}\n",
    "'''.format(testLoss, testAcc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>*Optional - Fine tune model with two-step training*</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "\n",
    "mobile.trainable = True\n",
    "\n",
    "for layer in mobile.layers[:-2]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "#re-train the model at a very low learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.00006), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "result = model.fit(x=train, validation_data=validation, epochs=100, verbose=2, callbacks=[cb, es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Accuracy and Loss graph</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy\n",
    "plt.plot(result.history['accuracy'])\n",
    "plt.plot(result.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "#loss\n",
    "plt.plot(result.history['loss'])\n",
    "plt.plot(result.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classification report</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test, verbose=0)\n",
    "# predictions = predictions.reshape(1,-1)[0]\n",
    "lst = np.argmax(predictions, axis= 1)\n",
    "\n",
    "print(classification_report(test.classes, lst, target_names = test.class_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Confusion matrix</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = confusion_matrix(test.classes, lst)\n",
    "print(result)\n",
    "\n",
    "def plot_confusion_matrix(result, classes, cmap=plt.cm.Blues):\n",
    "    plt.subplots(figsize=(7, 7))\n",
    "    plt.imshow(result, interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation = 90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "   \n",
    "\n",
    "    thresh = result.max() / 2.\n",
    "    for i, j in itertools.product(range(result.shape[0]), range(result.shape[1])):\n",
    "        plt.text(j, i, result[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color = \"white\" if result[i, j] > thresh else \"black\")\n",
    "        \n",
    "    #current matplotlib version will cut off top and bottom of the matrix, \n",
    "    #hence the manual workaround - remove if matplotlib version does not cut off\n",
    "    b, t = plt.ylim() # discover bottom and top values\n",
    "    b += 0.5 # Add 0.5 to bottom\n",
    "    t -= 0.5 # Subtract 0.5 from top\n",
    "    plt.ylim(b, t) # update ylim(bottom, top) values\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix(result, list(test.class_indices.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Labels of wrong predictions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getErrors(test, predictions):\n",
    "    #get file names of all images in test data\n",
    "    names = test.filenames\n",
    "\n",
    "    #get IDs of all classes\n",
    "    allClassesID = test.classes\n",
    "\n",
    "    #get dictionary of classes and respective ID\n",
    "    classLabelDict = test.class_indices\n",
    "    \n",
    "    #list of the names of all classes\n",
    "    classLabels = list(classLabelDict.keys())\n",
    "\n",
    "    print(\"The list of classes: \", classLabels)\n",
    "\n",
    "    #get the most predicted class\n",
    "    predictedClasses = np.argmax(predictions, axis=1)\n",
    "\n",
    "    predictedErrors = np.where(predictedClasses != allClassesID)[0]\n",
    "\n",
    "    print(\"Number of errors = {}/{}\".format(len(predictedErrors),test.samples))\n",
    "\n",
    "    return classLabels, predictedErrors, names\n",
    "\n",
    "def showErrors(classLabels, predictedErrors, predictions, names):\n",
    "    # Show the errors\n",
    "    for i in range(len(errors)):\n",
    "        predictedClass = np.argmax(predictions[predictedErrors[i]])\n",
    "\n",
    "        predictedLabel = classLabels[predictedClass]\n",
    "\n",
    "        title = 'Original Picture : {}, Prediction : {}, Confidence/Percentage : {:.3f}'.format\\\n",
    "                (names[predictedErrors[i]].split('/')[0],predictedLabel, predictions[errors[i]][predictedClass])\n",
    "        print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the list of class labels, prediction errors and file names\n",
    "labels, errors, names = getErrors(test, predictions)\n",
    "\n",
    "#show wrongly predicted images, prediction and and the percentage (confidence)\n",
    "showErrors(labels, errors, predictions, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the directory back to initial path (Image Classification folder)\n",
    "os.chdir(\"../..\")\n",
    "# os.listdir()\n",
    "\n",
    "#save the model so that it can be passed to edge device\n",
    "model.save(\"image_classification.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
